{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Statistical Testing\n",
    "You did it! You made it to week four. We've saved one of the best (and hardest) lessons for last. This lesson will cover statistical testing within Jupyter Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.giphy.com/media/TN0irsCox4F2nifYXC/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages\n",
    "Let's go ahead and import the necessary packages. Again, we'll go ahead and import Numpy and Pandas. This time around, we'll also be importing **SciPy**. Speficically, we'll be importing the **subpackage** stats from SciPy. All a subpackage is is a package within another package. We'll import the SciPy package, and you can try importing Pandas and Matplotlib yourself below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciPy\n",
    "SciPy, short for Scientific Python is a package that allows us to use scientific and mathematic tools for working with data. It works extremely well with Pandas and NumPy since it was created by the same developers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "\n",
    "# TODO: Import pandas (with the alias pd)\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Import matplotlib's pyploy (with the alias plt)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block below ensures whenever and wherever we run the code, the same random numbers are generated regardless. Be sure to check out the video below if you'd like to learn more about what this package, and random number generators in general, do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "`<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GtOt7EBNEwQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Data\n",
    "Again, we'll be working with the DSNY NEON site data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/Sci-Teens/ecology-program/main/data/dsny_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Examine first five values in the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we would need to determine, is whether or not our variation in data is due to random chance.The way statisticians quantify this variation is through **mean tests**. Mean tests measure whether or not the results we see are **statistically significant** or simply due to **chance error**. The way they do this is by measuring the probability of getting our results under the assumptions we have made with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a Histogram to look at how our data is distributed, for the temperatures throughout the month of June in 2020. We'll also use a special method called `dropna()` to drop values that are missing from our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "june_data = data.loc[(data['time'] > '2020-05-31') & (data['time'] <= '2020-06-30')]\n",
    "june_data = june_data.dropna(subset=['temperature_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a histogram of the June mean temperatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also repeat this for the month of December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_data = data.loc[(data['time'] > '2020-11-30') & (data['time'] <= '2020-12-31')]\n",
    "december_data = december_data.dropna(subset=['temperature_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a histogram of the December mean temperatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a **T-test** to examine whether there is a **statistically significant** difference in the mean temperatures for the two time frames besides simply looking at a histogram. T-tests take into account the mean and the variance of two variables to determine whether they are similar or different. Running a T-test gives us a **P-value** which is the probability that we got this value from random chance.\n",
    "\n",
    "First, let's look at the mean mean temperatures for December and June 2020 (hehe, mean mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean of the mean temperatures for June\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the mean of the mean temperatures for December\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the histograms and the means that we calculated, we can begin to believe that there is a significant difference between the distribution of mean temperatures throughout the months of December and June. We can further support our inference by usings using the `stats.ttest_ind` method to conduct and independent t-test on our two data columns. \n",
    "\n",
    "**NOTE** you may have noticed the `equal_var=False` argument set below. This has to do with the **variance** of our data. Though we won't go much into the variance represents, you can think of it as describing how spread out our data is. As we can see from the histogram above, our data is not equally spread out, and thus, our data does not have equal variances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(june_data['temperature_mean'], december_data['temperature_mean'], equal_var=False)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this p-value, we can safetly assume that there is a significant difference between the mean temperature in the months of June and December"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last type of statistical testing that we'll cover today is the **Correlation Test**. This allows us to see how much of a relationship two data columns have. However, data can have many forms of correlation. The most typical correlationship that is tested for is a **Linear Relationship**. Don't worry about the code itself for now, just take a look at the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x + random.random() for x in range(10)]\n",
    "Y = [y for y in range(10)]\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our data forms what appears to be a line. The line is also pointing upward, which suggests a **positive correlation** between the x and y data. A positive correlation means that when one variable increases, the other variable is expected to increase as well. We can view this by plotting the line \\$y = x\\$ over our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,10],[0,10])\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the points that we plotted fall very close to the line. Next, we'll check out what is called a **negative correlation**. A negative correlation means that when one variable increases, we expect the other variable to decrease. Again, don't worry as much about the code than the plot itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When plot this data with the line \\$ y = -x + 10 \\$ through it, we can better see the negative relationship in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, [10 - y for y in Y])\n",
    "plt.plot([0,10], [10,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ways to compare different types of correlations. The most common on you will is the called the **Pearson Correlation Coefficient** which simply measures how strong of a linear relationship two variables have. Another way to think of this correlation coefficient as being related to the slope of the line of best fit.<br> A perfect, positive linear relationship would result in a **Correlation Coefficient** of 1, whereas a perfect negative linear relationship would result in a correlation coefficient of -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data above, we can see that the first graph is very strongly linearly correlated and we would expect a correlation coefficient closer to 1. In the second graph, they are negatively correlated so correlation coefficient is going to be close to -1. Because the absolute value of our coefficients are close to 1, we could say that our data is **strongly linearly correlated**. This means a linear pattern describes our data well. However, if we had data such as below, we would say that our correlation coefficient is small and close to 0. Therefore, we would say that our data has a **weak linear correlation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([x+10 * (random.random()-.5) for x in range(10)] , Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if there's a correlation between the humidity and precipitation at the DSNY NEON Site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot mean relative humidity versus bulk precipitation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, Pandas already has a `corr()` method built in, so we don't even have to bother with using SciPy for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relative_humidity_mean'].corr(data['precipitation_bulk'], method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got a correlation coefficient of 0.07. This is close to zero, which suggests that there is a very weak linear relationship between these data. This is evident in our plot above, so no surprises here. Next, we'll try a **Spearman Correlation**, which simply measures how related two data points are. The benefit of using the Spearman Correlation is that the data doesn't have to be linear, all it has to have is some form of a relationship that follows a line or a curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['relative_humidity_mean'].corr(data['precipitation_bulk'], method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get a stronger correlation value than the Pearson Correlation since our data is not linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "That was our last and hardest lesson yet, so props for making it through the course! Let's go ahead and practice the skills and techniques we learned today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question One\n",
    "Let's determine if there's any correlation between the Bulk precipitation and mean temperature. This problem is three-fold: First, we'll create a scatterplot of our data to view the relation between mean temperature and bulk precipitation. Then, we'll go ahead and conduct both a Pearson and a Spearman Correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a scatterplot of mean temperature and bulk precipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the Pearson correlation between mean temperature and bulk precipitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the Spearman correlation between mean temperature and bulk precipitation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Two\n",
    "Let's see if the mean temperature in the months of June and July. This problem is three-fold: First, we'll create a histogram of our data to view the distribution temperatures. Then, we'll go ahead and compute a t-test to see how the distributions of these data compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of the June mean temperature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram of the July mean temperature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform a T-test to compare the mean temperatures for each month\n",
    "# Make sure to compute an independent T-test, and assume that \n",
    "# these distributions don't have the same variance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
